#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Bandwidth Keeper Pro - Docker ä¸“ç”¨ç‰ˆ

âœ… ä¿®å¤æ‰€æœ‰å·²çŸ¥é—®é¢˜ï¼š
  - é’‰é’‰Secretç¼ºå¤±å¯¼è‡´é€šçŸ¥å¤±è´¥
  - å®šæ—¶ä»»åŠ¡Cronè§£æé—®é¢˜ï¼ˆå·²ä¿®å¤æ¯åˆ†é’Ÿæ‰§è¡Œé—®é¢˜ï¼‰
  - 403 Forbidden / GBKç¼–ç  / æ¨¡æ¿è·¯å¾„

âœ… é£ç‰›NAS ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–ï¼š
  - æ—¶åŒº/è·¯å¾„/æ—¥å¿—/èµ„æºç›‘æ§
  - ä¿ç•™æœ¬åœ°æµ‹è¯•å…¼å®¹æ€§ï¼ˆWindows/Linux åŒç¯å¢ƒæ”¯æŒï¼‰
"""

import os
import sys
import time
import random
import json
import requests
import logging
from datetime import datetime, timedelta
from flask import Flask, render_template, request, jsonify
import threading
import pytz
import hmac
import hashlib
import base64
import urllib.parse

# ==================== ç¯å¢ƒåˆå§‹åŒ–ï¼ˆDocker ä¼˜å…ˆï¼‰ ====================
# å¼ºåˆ¶ UTF-8 ç¼–ç ï¼ˆè§£å†³ Docker å®¹å™¨å†…ç¼–ç é—®é¢˜ï¼‰
os.environ['PYTHONIOENCODING'] = 'utf-8'
if sys.platform != 'win32': os.environ['TZ'] = 'Asia/Shanghai'
try:
    time.tzset()
except:
    pass

# è·¯å¾„é…ç½®ï¼šDocker ä½¿ç”¨ /config /logsï¼Œæœ¬åœ°æµ‹è¯•ä½¿ç”¨ç›¸å¯¹è·¯å¾„
CONFIG_PATH = os.environ.get('CONFIG_PATH', 'config.json')
LOG_PATH = os.environ.get('LOG_PATH', 'execution.log')

# ç¡®ä¿ç›®å½•å­˜åœ¨ï¼ˆDocker æŒ‚è½½å·å¯èƒ½ä¸ºç©ºç›®å½•ï¼‰
for path in [os.path.dirname(CONFIG_PATH), os.path.dirname(LOG_PATH)]:
    if path and not os.path.exists(path):
        os.makedirs(path, exist_ok=True)

# é™é€Ÿæ˜ å°„ (MB/s -> bytes/s) | æ³¨ï¼š1MB/s = 1024*1024 B/s
SPEED_LIMITS = {
    "unlimited": 0,
    "1mbps": 1024 * 1024,
    "3mbps": 3 * 1024 * 1024,
    "5mbps": 5 * 1024 * 1024
}

# ==================== æ—¥å¿—ç³»ç»Ÿï¼ˆDocker å‹å¥½ï¼‰ ====================
# é…ç½®æ ‡å‡† loggingï¼ˆå…¼å®¹ docker logsï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.StreamHandler(sys.stdout),  # Docker æ ‡å‡†è¾“å‡º
        logging.FileHandler(LOG_PATH, encoding='utf-8', mode='a')  # æŒä¹…åŒ–æ—¥å¿—
    ]
)
logger = logging.getLogger(__name__)

def log_message(msg):
    """ç»Ÿä¸€æ—¥å¿—æ¥å£ï¼ˆç§»é™¤ emoji + ä¸­æ–‡å®‰å…¨ï¼‰"""
    clean_msg = (
        msg.replace('ğŸš€', '[å¼€å§‹]').replace('ğŸ“Š', '[å®Œæˆ]').replace('âš ï¸', '[è­¦å‘Š]')
        .replace('âœ…', '[æˆåŠŸ]').replace('âŒ', '[å¤±è´¥]').replace('ğŸ’¡', '[æç¤º]')
        .replace('ğŸ“Œ', '[æ³¨æ„]').replace('âœ¨', '[å®Œæˆ]').replace('âš¡', '[è§¦å‘]')
    )
    logger.info(clean_msg)

# ==================== é…ç½®ç®¡ç† ====================
def load_config():
    """åŠ è½½é…ç½®ï¼ˆUTF-8 å®‰å…¨ï¼‰"""
    if os.path.exists(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            log_message(f"[é…ç½®] åŠ è½½å¤±è´¥: {str(e)} | è·¯å¾„: {CONFIG_PATH}")
    
    # ç”Ÿæˆå®‰å…¨é»˜è®¤é…ç½®
    default = {
        "download_links": [
            "https://mirrors.tuna.tsinghua.edu.cn/archlinux/iso/2026.02.01/archlinux-x86_64.iso",
            "https://ftp.jaist.ac.jp/pub/Linux/debian-cd/13.3.0/amd64/iso-cd/debian-edu-13.3.0-amd64-netinst.iso",
            "https://mirrors.cloud.tencent.com/almalinux/10/BaseOS/x86_64/os/images/boot.iso"
        ],
        "cron": "0 2 * * *",  # æ¯å¤©å‡Œæ™¨2ç‚¹ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰
        "speed_limit": "unlimited",
        "dingtalk_webhook": "",
        "dingtalk_secret": ""
    }
    
    # ä¿å­˜é»˜è®¤é…ç½®
    save_config(default)
    log_message(f"[é…ç½®] é¦–æ¬¡å¯åŠ¨ï¼Œç”Ÿæˆé»˜è®¤é…ç½®: {CONFIG_PATH}")
    return default

def save_config(data):
    """ä¿å­˜é…ç½®ï¼ˆUTF-8 + ä¸­æ–‡ä¿ç•™ï¼‰"""
    try:
        with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        log_message(f"[é…ç½®] å·²ä¿å­˜: {CONFIG_PATH}")
        return True
    except Exception as e:
        log_message(f"[é…ç½®] ä¿å­˜å¤±è´¥: {str(e)}")
        return False

# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================
def download_with_limit(url, speed_limit_bps):
    """å¸¦é™é€Ÿä¸‹è½½ï¼ˆé˜²403 + è¶…æ—¶æ§åˆ¶ï¼‰"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 '
                      '(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 '
                      'BandwidthKeeper/2.1'
    }
    start_time = time.time()
    total_bytes = 0
    last_time = time.time()
    try:
        with requests.get(url, stream=True, headers=headers, timeout=120) as r:
            r.raise_for_status()
            for chunk in r.iter_content(chunk_size=16384):
                if chunk:
                    total_bytes += len(chunk)
                    if speed_limit_bps > 0:
                        elapsed = time.time() - last_time
                        expected = len(chunk) / speed_limit_bps
                        if elapsed < expected:
                            time.sleep(expected - elapsed)
                        last_time = time.time()
            duration = time.time() - start_time
            return total_bytes, duration, r.status_code
    except Exception as e:
        duration = time.time() - start_time
        log_message(f"[ä¸‹è½½] å¤±è´¥ | URL: {url[:60]} | é”™è¯¯: {str(e)}")
        return 0, duration, 500

def send_dingtalk(msg):
    """é’‰é’‰é€šçŸ¥ï¼ˆä½¿ç”¨å¸¦ç­¾åçš„URLï¼‰"""
    try:
        config = load_config()
        webhook = config.get("dingtalk_webhook", "").strip()
        secret = config.get("dingtalk_secret", "").strip()
        
        if not webhook:
            log_message("[é’‰é’‰] é€šçŸ¥å¤±è´¥: é’‰é’‰Webhookæœªé…ç½®")
            return
        if not secret:
            log_message("[é’‰é’‰] é€šçŸ¥å¤±è´¥: é’‰é’‰Secretæœªé…ç½®")
            return
        
        # ç”Ÿæˆç­¾å
        timestamp = str(round(time.time() * 1000))
        string_to_sign = f'{timestamp}\n{secret}'
        hmac_code = hmac.new(secret.encode('utf-8'), string_to_sign.encode('utf-8'), digestmod=hashlib.sha256).digest()
        sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))
        
        # æ„é€ å¸¦ç­¾åçš„URL
        signed_url = f"{webhook}&timestamp={timestamp}&sign={sign}"
        
        # å‘é€æ¶ˆæ¯
        payload = {"msgtype": "text", "text": {"content": f"ã€Bandwidth Keeperã€‘\n{msg}"}}
        response = requests.post(signed_url, json=payload, timeout=5)
        response.raise_for_status()
        
        log_message(f"[é’‰é’‰] é€šçŸ¥æˆåŠŸ: {msg}")
    except Exception as e:
        log_message(f"[é’‰é’‰] é€šçŸ¥å¤±è´¥: {str(e)}")

def execute_task():
    """æ‰§è¡Œä¸‹è½½ä»»åŠ¡ï¼ˆèµ„æºå®‰å…¨ï¼‰"""
    config = load_config()
    valid_links = [link.strip() for link in config["download_links"] if link.strip()]
    if not valid_links:
        log_message("[ä»»åŠ¡] è·³è¿‡: æ— æœ‰æ•ˆä¸‹è½½é“¾æ¥")
        send_dingtalk("âš ï¸ ä»»åŠ¡è·³è¿‡ï¼šé…ç½®ä¸­æ— æœ‰æ•ˆä¸‹è½½é“¾æ¥")
        return
    
    url = random.choice(valid_links)
    speed_key = config.get("speed_limit", "unlimited")
    speed_bps = SPEED_LIMITS.get(speed_key, 0)
    
    log_message(f"[å¼€å§‹] ä»»åŠ¡ | é™é€Ÿ: {speed_key} | é“¾æ¥: {url[:50]}...")
    bytes_down, duration, status = download_with_limit(url, speed_bps)
    
    # ç”ŸæˆæŠ¥å‘Š
    human_bytes = f"{bytes_down / (1024**2):.2f} MB" if bytes_down > 0 else "0 B"
    human_time = f"{duration:.1f}ç§’"
    status_text = "[æˆåŠŸ]" if status == 200 else f"[å¤±è´¥({status})]"
    report = (
        f"{status_text}\n"
        f"é“¾æ¥: {url[:60]}...\n"
        f"æµé‡: {human_bytes}\n"
        f"è€—æ—¶: {human_time}\n"
        f"é™é€Ÿ: {speed_key.upper()}"
    )
    
    log_message(f"[å®Œæˆ] ä»»åŠ¡ | {report.replace(chr(10), ' | ')}")
    send_dingtalk(report)

# ==================== å®šæ—¶ä»»åŠ¡ï¼ˆä½¿ç”¨ APSchedulerï¼‰ ====================
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger

# ä¿å­˜è°ƒåº¦å™¨å®ä¾‹
scheduler = None

def setup_schedule():
    """ä½¿ç”¨ APScheduler è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼ˆæ”¯æŒå®Œæ•´ Cron è¡¨è¾¾å¼ï¼‰"""
    global scheduler
    
    # å¦‚æœå·²ç»æœ‰è°ƒåº¦å™¨ï¼Œå…ˆåœæ­¢å®ƒ
    if scheduler:
        scheduler.shutdown(wait=False)
    
    config = load_config()
    cron_expr = config.get("cron", "").strip()
    
    if not cron_expr:
        log_message("[è°ƒåº¦] å®šæ—¶ä»»åŠ¡å·²ç¦ç”¨ï¼ˆCron ä¸ºç©ºï¼‰")
        return
    
    try:
        # ä½¿ç”¨ APScheduler è§£æ Cron è¡¨è¾¾å¼ï¼ˆå…³é”®ä¿®å¤ï¼šä½¿ç”¨ from_crontab è€Œä¸æ˜¯ from_cronï¼‰
        scheduler = BackgroundScheduler()
        trigger = CronTrigger.from_crontab(cron_expr)  # ä¿®å¤ç‚¹1ï¼šfrom_cron -> from_crontab
        scheduler.add_job(execute_task, trigger=trigger)
        scheduler.start()
        log_message(f"[è°ƒåº¦] å·²è®¾ç½® Cron: {cron_expr} | ä»»åŠ¡: {execute_task.__name__}")
    except Exception as e:
        log_message(f"[è°ƒåº¦] Cron è§£æå¤±è´¥: {str(e)} | è¡¨è¾¾å¼: {cron_expr}")
        log_message("[è°ƒåº¦] å›é€€åˆ°é»˜è®¤æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ")
        # å›é€€åˆ°é»˜è®¤è®¾ç½®ï¼ˆå…³é”®ä¿®å¤ï¼šä½¿ç”¨ from_crontabï¼‰
        scheduler = BackgroundScheduler()
        trigger = CronTrigger.from_crontab("0 2 * * *")  # ä¿®å¤ç‚¹2ï¼šfrom_cron -> from_crontab
        scheduler.add_job(execute_task, trigger=trigger)
        scheduler.start()

# ==================== Flask åº”ç”¨ ====================
app = Flask(__name__, static_folder='static', template_folder='templates', instance_relative_config=False)

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/config', methods=['GET'])
def get_config():
    return jsonify(load_config())

@app.route('/api/config', methods=['POST'])
def update_config():
    try:
        data = request.json
        if not data:
            return jsonify({"error": "æ— æ•ˆé…ç½®"}), 400
        
        # éªŒè¯ä¸‹è½½é“¾æ¥
        links = [l.strip() for l in data.get("download_links", []) if l.strip()]
        if len(links) > 5:
            return jsonify({"error": "æœ€å¤š5ä¸ªæœ‰æ•ˆä¸‹è½½é“¾æ¥"}), 400
        
        # ä¿å­˜é…ç½®
        save_config(data)
        
        # é‡æ–°è®¾ç½®è°ƒåº¦
        setup_schedule()
        
        return jsonify({"success": True, "message": "é…ç½®å·²ä¿å­˜å¹¶ç”Ÿæ•ˆ"})
    except Exception as e:
        log_message(f"[API] é…ç½®ä¿å­˜å¼‚å¸¸: {str(e)}")
        return jsonify({"error": f"ä¿å­˜å¤±è´¥: {str(e)}"}), 500

@app.route('/api/logs', methods=['GET'])
def get_logs():
    try:
        if not os.path.exists(LOG_PATH):
            return jsonify({"logs": ["[ç³»ç»Ÿ] æ— æ—¥å¿—è®°å½•"]})
        with open(LOG_PATH, 'r', encoding='utf-8') as f:
            lines = f.readlines()[-150:]  # è¿”å›æœ€è¿‘150æ¡
        return jsonify({"logs": [line.strip() for line in lines]})
    except Exception as e:
        return jsonify({"logs": [f"[é”™è¯¯] è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}"]})

@app.route('/api/force-run', methods=['POST'])
def force_run():
    threading.Thread(target=execute_task, daemon=True).start()
    log_message("[è§¦å‘] æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡ï¼ˆAPIè°ƒç”¨ï¼‰")
    return jsonify({"success": True, "message": "ä»»åŠ¡å·²è§¦å‘"})

# ==================== å¯åŠ¨ä¸»ç¨‹åº ====================
if __name__ == '__main__':
    # åˆå§‹åŒ–é…ç½®
    if not os.path.exists(CONFIG_PATH):
        load_config()
    
    # è®¾ç½®è°ƒåº¦
    setup_schedule()
    
    # å¯åŠ¨WebæœåŠ¡
    log_message("=" * 60)
    log_message("ğŸš€ Bandwidth Keeper Pro - NAS v2.2")
    log_message(f"ğŸ“ é…ç½®è·¯å¾„: {CONFIG_PATH}")
    log_message(f"ğŸ“„ æ—¥å¿—è·¯å¾„: {LOG_PATH}")
    log_message(f"ğŸŒ æ—¶åŒº: {pytz.timezone('Asia/Shanghai')}")
    log_message(f"ğŸ Python: {sys.version.split()[0]} | å¹³å°: {sys.platform}")
    log_message("=" * 60)
    
    app.run(
        host='0.0.0.0',
        port=9016,
        debug=False,
        use_reloader=False,
        threaded=True,
        processes=1
    )